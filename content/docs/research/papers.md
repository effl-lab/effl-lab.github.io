---
title: Papers
type: docs
bookToc: true
weight: 2
---


We mainly target top-tier ML conferences, and other domain-specific venues that involve ML.  

---
### **2025**

- **Towards Federated Low-Rank Adaptation with Rank-Heterogeneous Communication**  
  Yuji Byun and Jaeho Lee  
  *NAACL 2025* (NeurIPS 2024 AFM Workshop) [[paper](https://arxiv.org/abs/2406.17477)]

- **Fast Training of Sinusoidal Neural Fields via Scaling Initialization**  
  Taesun Yeom,<sup>\*</sup> Sangyoon Lee,<sup>\*</sup> and Jaeho Lee  
  *ICLR 2025* [[paper](https://openreview.net/forum?id=Sr5XaZzirA)]

- **ZIP: An Efficient Zeroth-order Prompt Tuning for Black-box Vision-Language Models**  
  Seonghwan Park, Jaehyeon Jeong, Yongjun Kim, Jaeho Lee, and Namhoon Lee  
  *ICLR 2025* [[paper](https://openreview.net/forum?id=2OegVbwvY2)]

- **AudioBERT: Audio Knowledge Augmented Language Model**  
  Hyunjong Ok,<sup>\*</sup> Suho Yoo,<sup>\*</sup> and Jaeho Lee  
  *ICASSP 2025* (Outstanding paper award üèÜ @ JKAIA 2024) [[paper](https://arxiv.org/abs/2409.08199)] [[code](https://github.com/HJ-Ok/AudioBERT)] [[dataset](https://github.com/HJ-Ok/AudioBERT/tree/main/dataset)]

- **Communication-Efficient Split Learning via Adaptive Feature-wise Compression**  
  Yongjeong Oh, Jaeho Lee, Christopher G. Brinton, and Yo-Seb Jeon  
  *IEEE TNNLS* [[paper](https://arxiv.org/abs/2307.10805)]

- **On the Internal Representations of Graph Metanetworks**  
  Taesun Yeom and Jaeho Lee  
  *ICLR 2025 Workshop*: Weight Space Learning [[paper](https://openreview.net/forum?id=WAyD9ZPuk6)]

- **Prompt-based Depth Pruning of Large Language Models**  
  Juyun Wee,<sup>\*</sup> Minjae Park,<sup>\*</sup> and Jaeho Lee  
  arXiv 2502.04348 [[paper](https://arxiv.org/abs/2502.04348)]

- **Imagine to Hear: Auditory Knowledge Generation can be an Effective Assistant for Language Models**  
  Suho Yoo,<sup>\*</sup> Hyunjong Ok,<sup>\*</sup> and Jaeho Lee  
  arXiv 2503.16853 [[paper](https://www.arxiv.org/abs/2503.16853)]

### **2024**

- **Decoding with Limited Teacher Supervision Requires Understanding When to Trust the Teacher**  
  Hyunjong Ok, Jegwang Ryu and Jaeho Lee  
  *EMNLP 2024* [[paper](https://arxiv.org/abs/2406.18002)]

- **Prefixing Attention Sinks can Mitigate Activation Outliers for Large Language Model Quantization**  
  Seungwoo Son, Wonpyo Park, Woohyun Han, Kyuyeun Kim, and Jaeho Lee  
  *EMNLP 2024* [[paper](https://arxiv.org/abs/2406.12016)]

- **Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization**  
  Sungbin Shin, Wonpyo Park, Jaeho Lee, and Namhoon Lee  
  *EMNLP 2024* [[paper](https://arxiv.org/abs/2406.15524)]

- **The Role of Masking for Efficient Supervised Knowledge Distillation of Vision Transformers**  
  Seungwoo Son, Jegwang Ryu, Namhoon Lee, and Jaeho Lee  
  *ECCV 2024* (ICLR 2023 Sparsity Workshop, Outstanding paper award ü•â @ IPIU 2023) [[paper](https://arxiv.org/abs/2302.10494)] [[project page](https://maskedkd.github.io/)] [[code](https://github.com/effl-lab/MaskedKD)]

- **Neural Image Compression with Text-guided Encoding for both Pixel-level and Perceptual Fidelity**  
  Hagyeong Lee,<sup>\*</sup> Minkyu Kim,<sup>\*</sup> Jun-Hyuk Kim, Seungeon Kim, Dokwan Oh, and Jaeho Lee  
  *ICML 2024* [[paper](https://arxiv.org/abs/2403.02944)] [[project page](https://taco-nic.github.io/)] [[code](https://github.com/effl-lab/TACO)]

- **Hybrid Neural Representations for Spherical Data**  
  Hyomin Kim, Yunhui Jang, Jaeho Lee, and Sungsoo Ahn  
  *ICML 2024* [[paper](https://arxiv.org/abs/2402.05965)]

- **In Search of a Data Transformation that Accelerates Neural Field Training**  
  Junwon Seo,<sup>\*</sup> Sangyoon Lee,<sup>\*</sup> Kwang In Kim, and Jaeho Lee  
  *CVPR 2024* `Oral (top 0.78%)` (NeurIPS 2023 ATTRIB Workshop) [[paper](https://arxiv.org/abs/2311.17094)] [[code](https://github.com/effl-lab/DT4Neural-Field)] [[demo](https://huggingface.co/spaces/lyunm1206/Interactive_Loss_Landscapes)]

- **Discovering and Mitigating Visual Biases through Keyword Explanation**  
  Younghyun Kim,<sup>\*</sup> Sangwoo Mo,<sup>\*</sup> Minkyu Kim, Kyungmin Lee, Jaeho Lee, and Jinwoo Shin  
  *CVPR 2024* `Highlight (top 2.8%)` (ICML 2023 SCIS Workshop) [[paper](https://arxiv.org/abs/2301.11104)] [[code](https://github.com/alinlab/b2t)]

- **SCANNER: Knowledge-Enhanced Approach for Robust Multi-modal Named Entity Recognition of Unseen Entities**  
  Hyunjong Ok, Taeho Kil, Sukmin Seo, and Jaeho Lee  
  *NAACL 2024* [[paper](https://arxiv.org/abs/2404.01914)]

- **Few-shot Unlearning**  
  Youngsik Yoon, Jinhwan Nam, Hyojeong Yun, Jaeho Lee, Dongwoo Kim, and Jungseul Ok  
  *IEEE S&P 2024* [[paper](https://arxiv.org/abs/2205.15567)]

- **Attention-aware Semantic Communications for Collaborative Inference**  
  Jiwoong Im,<sup>\*</sup> Nayoung Kwon,<sup>\*</sup> Taewoo Park, Jiheon Woo, Jaeho Lee, and Yongjune Kim  
  *IEEE IoT Journal* (IEEE Communication Theory Workshop 2024) [[paper](https://arxiv.org/abs/2404.07217)]

- **S2Cap: A Benchmark and a Baseline for Singing Style Captioning**  
  Hyunjong Ok and Jaeho Lee  
  arXiv 2409.09866 [[paper](https://arxiv.org/abs/2409.09866)] [[dataset](https://github.com/HJ-Ok/S2cap)]


### **2023**

- **Learning Large-scale Neural Fields via Context Pruned Meta-learning**  
  Jihoon Tack, Subin Kim, Sihyun Yu, Jaeho Lee, Jinwoo Shin, and Jonathan R. Schwarz  
  *NeurIPS 2023* (ICLR 2023 Neural Fields Workshop) [[paper](https://arxiv.org/abs/2302.00617)] [[code](https://github.com/jihoontack/GradNCP)]

- **Modality-Agnostic Variational Compression of Implicit Neural Representations**  
  Jonathan R. Schwarz, Jihoon Tack, Yee Whye Teh, Jaeho Lee, and Jinwoo Shin  
  *ICML 2023* (ICLR 2023 Neural Fields Workshop) [[paper](https://openreview.net/forum?id=bBXCCSoVQZ)]

- **Breaking the Spurious Causality of Conditional Generation via Fairness Intervention with Corrective Sampling**  
  Junhyun Nam, Sangwoo Mo, Jaeho Lee, and Jinwoo Shin  
  *TMLR 2023* (ICML 2023 SCIS Workshop) [[paper](https://openreview.net/forum?id=VV4zJwLwI7)]

- **Semi-Ensemble: A Simple Approach to Over-Parameterize Model Interpolation**  
  Jiwoon Lee and Jaeho Lee  
  *NeurIPS 2023 Workshop*: UniReps [[paper](https://unireps.org)]

- **On the Effectiveness of Sharpness-aware Minimization with Large Mini-batches**  
  Jinseok Chung, Seonghwan Park, Jaeho Lee, and Namhoon Lee  
  *ICML 2023 Workshop*: HDLD [[paper](https://icml.cc/virtual/2023/25899)]

- **Debiased Distillation by Transplanting the Last Layer**  
  Jiwoon Lee and Jaeho Lee  
  arXiv 2302.11187 (IPIU 2023) [[paper](https://arxiv.org/abs/2302.11187)]


### **2022**

- **Scalable Neural Video Representations with Learnable Positional Features**  
  Subin Kim, Sihyun Yu, Jaeho Lee, and Jinwoo Shin  
  *NeurIPS 2022* [[paper](https://openreview.net/forum?id=OxfI-3i5M8g)] [[project page](https://subin-kim-cv.github.io/NVP/)]

- **Meta-learning with Self-improving Momentum Targets**  
  Jihoon Tack, Jongjin Park, Hankook Lee, Jaeho Lee and Jinwoo Shin  
  *NeurIPS 2022* [[paper](https://openreview.net/forum?id=FCNMbF_TsKm)]

- **Spread Spurious Attribute: Improving Worst-Group Accuracy with Spurious Attribute Estimation**  
  Junhyun Nam, Jaehyung Kim, Jaeho Lee, and Jinwoo Shin  
  *ICLR 2022* [[paper](https://openreview.net/forum?id=_F9xpOrqyX9)]

- **Zero-shot Blind Image Denoising via Implicit Neural Representations**  
  Chaewon Kim, Jaeho Lee, and Jinwoo Shin  
  arXiv 2204.02405 [[paper](https://arxiv.org/abs/2204.02405)]


### **2021**

- **Meta-learning Sparse Implicit Neural Representations**  
  Jaeho Lee, Jihoon Tack, Namhoon Lee, and Jinwoo Shin  
  *NeurIPS 2021* [[paper](https://openreview.net/forum?id=Tn0PnRY877g)]

- **Co2L: Contrastive Continual Learning**  
  Hyuntak Cha, Jaeho Lee, and Jinwoo Shin  
  *ICCV 2021* [[paper](https://openaccess.thecvf.com/content/ICCV2021/html/Cha_Co2L_Contrastive_Continual_Learning_ICCV_2021_paper.html)]

- **Provable Memorization via Deep Neural Networks using Sub-linear Parameters**  
  Sejun Park, Jaeho Lee, Chulhee Yun, and Jinwoo Shin  
  *COLT 2021* (DeepMath 2020 `Oral`) [[paper](https://proceedings.mlr.press/v134/park21a.html)]

- **Minimum Width for Universal Approximation**  
  Sejun Park, Chulhee Yun, Jaeho Lee, and Jinwoo Shin  
  *ICLR 2021* `Spotlight` (DeepMath 2020 `Oral`) [[paper](https://openreview.net/forum?id=O-XJwyoIF-k)]

- **Layer-adaptive Sparsity for the Magnitude-based Pruning**  
  Jaeho Lee, Sejun Park, Sangwoo Mo, Sungsoo Ahn, and Jinwoo Shin  
  *ICLR 2021* [[paper](https://openreview.net/forum?id=H6ATjJ0TKdf)]

- **MASKER: Masked Keyword Regularization for Reliable Text Generation**  
  Seung Jun Moon, Sangwoo Mo, Kimin Lee, Jaeho Lee, and Jinwoo Shin  
  *AAAI 2021* [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/17601)]

- **Greedyprune: Layer-wise Optimization Algorithms for Magnitude-based Pruning**  
  Vinoth Nandakumar and Jaeho Lee  
  *Sparse Neural Network Workshop 2021* [[paper](https://sites.google.com/view/sparsity-workshop-2021/accepted-papers)]


### **2020**

- **Learning Bounds for Risk-sensitive Learning**  
  Jaeho Lee, Sejun Park, and Jinwoo Shin  
  *NeurIPS 2020* [[paper](https://proceedings.neurips.cc/paper/2020/hash/9f60ab2b55468f104055b16df8f69e81-Abstract.html)]

- **Learning from Failure: Training Debiased Classifier from Biased Classifier**  
  Junhyun Nam, Hyuntak Cha, Sungsoo Ahn, Jaeho Lee, and Jinwoo Shin  
  *NeurIPS 2020* [[paper](https://papers.nips.cc/paper_files/paper/2020/hash/eddc3427c5d77843c2253f1e799fe933-Abstract.html)]

- **Lookahead: A Far-sighted Alternative of Magnitude-based Pruning**  
  Sejun Park,<sup>\*</sup> Jaeho Lee,<sup>\*</sup> Sangwoo Mo, and Jinwoo Shin  
  *ICLR 2020* [[paper](https://openreview.net/forum?id=ryl3ygHYDB)]


### **Pre-2020**

- **Learning Finite-dimensional Coding Schemes with Nonlinear Reconstruction Maps**  
  Jaeho Lee and Maxim Raginsky  
  *SIMODS 2019* [[paper](https://epubs.siam.org/doi/10.1137/18M1234461)]

- **Minimax Statistical Learning with Wasserstein Distances**  
  Jaeho Lee and Maxim Raginsky  
  *NeurIPS 2018* `Spotlight` [[paper](https://papers.nips.cc/paper_files/paper/2018/hash/ea8fcd92d59581717e06eb187f10666d-Abstract.html)]

- **On MMSE Estimation from Quantized Observations in the Nonasymptotic Regime**  
  Jaeho Lee, Maxim Raginsky, and Pierre Moulin  
  *ISIT 2015* [[paper](https://ieeexplore.ieee.org/document/7282992)]

---
### **Domestic Posters üêØ**

- **An Empirical Study on the Bias of Generative Image Compression**  
  Hagyeong Lee and Jaeho Lee  
  *IPIU 2023*

- **Is Sparse Identification Model Sufficiently Biased?**  
  Junwon Seo and Jaeho Lee  
  *IPIU 2023*