<!DOCTYPE html>
<html lang="en" dir="ltr">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="We mainly target top-tier ML conferences, and other domain-specific venues that involve ML.
2025 # Towards Federated Low-Rank Adaptation with Rank-Heterogeneous Communication
Yuji Byun and Jaeho Lee
NAACL 2025 (NeurIPS 2024 AFM Workshop)
Fast Training of Sinusoidal Neural Fields via Scaling Initialization
Taesun Yeom,* Sangyoon Lee,* and Jaeho Lee
ICLR 2025
ZIP: An Efficient Zeroth-order Prompt Tuning for Black-box Vision-Language Models
Seonghwan Park, Jaehyeon Jeong, Yongjun Kim, Jaeho Lee, and Namhoon Lee">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="#343a40">
<meta name="color-scheme" content="light dark"><meta property="og:title" content="Papers" />
<meta property="og:description" content="We mainly target top-tier ML conferences, and other domain-specific venues that involve ML.
2025 # Towards Federated Low-Rank Adaptation with Rank-Heterogeneous Communication
Yuji Byun and Jaeho Lee
NAACL 2025 (NeurIPS 2024 AFM Workshop)
Fast Training of Sinusoidal Neural Fields via Scaling Initialization
Taesun Yeom,* Sangyoon Lee,* and Jaeho Lee
ICLR 2025
ZIP: An Efficient Zeroth-order Prompt Tuning for Black-box Vision-Language Models
Seonghwan Park, Jaehyeon Jeong, Yongjun Kim, Jaeho Lee, and Namhoon Lee" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://effl.postech.ac.kr/docs/research/papers/" /><meta property="article:section" content="docs" />

<meta property="article:modified_time" content="2025-01-24T14:48:10+09:00" />
<title>Papers | EffL @ POSTECH</title>
<link rel="manifest" href="/manifest.json">
<link rel="icon" href="/favicon.png" >
<link rel="stylesheet" href="/book.min.f8de3645fe00591b41524aee174e19edd98a22255a2930a0cdc82a94835ba387.css" integrity="sha256-&#43;N42Rf4AWRtBUkruF04Z7dmKIiVaKTCgzcgqlINbo4c=" crossorigin="anonymous">
  <script defer src="/flexsearch.min.js"></script>
  <script defer src="/en.search.min.14458d5f4125de0becd271a59ff7b4fc9014e80450bbb359502a7a36407deade.js" integrity="sha256-FEWNX0El3gvs0nGln/e0/JAU6ARQu7NZUCp6NkB96t4=" crossorigin="anonymous"></script>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-5LN63JL26W"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-5LN63JL26W', { 'anonymize_ip': false });
}
</script>
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
  
</head>
<body dir="ltr">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/"><span>EffL @ POSTECH</span>
  </a>
</h2>


<div class="book-search">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>












  



  
  <ul>
    
      
        <li class="book-section-flat" >
          
  
  

  
    <span>Research</span>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/research/focus/" class="">Focus</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/research/papers/" class="active">Papers</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/research/collaborators/" class="">Collaborators</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <span>People</span>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/people/temp/" class=""> </a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/people/members/" class="">Members</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/people/intern/" class="">Interns</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/people/past/" class="">Alumni</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <span>How to Join?</span>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/How-to-Join/graduate/" class="">M.S./Ph.D. üéì</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/How-to-Join/interns/" class="">Interns üê•</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>















</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <strong>Papers</strong>

  <label for="toc-control">
    
    <img src="/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  
<nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li>
          <ul>
            <li><a href="#2025"><strong>2025</strong></a></li>
            <li><a href="#2024"><strong>2024</strong></a></li>
            <li><a href="#2023"><strong>2023</strong></a></li>
            <li><a href="#2022"><strong>2022</strong></a></li>
            <li><a href="#2021"><strong>2021</strong></a></li>
            <li><a href="#2020"><strong>2020</strong></a></li>
            <li><a href="#pre-2020"><strong>Pre-2020</strong></a></li>
            <li><a href="#domestic-posters-"><strong>Domestic Posters üêØ</strong></a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
  <article class="markdown"><p>We mainly target top-tier ML conferences, and other domain-specific venues that involve ML.</p>
<hr>
<h3 id="2025">
  <strong>2025</strong>
  <a class="anchor" href="#2025">#</a>
</h3>
<p><a href="https://arxiv.org/abs/2406.17477"><strong>Towards Federated Low-Rank Adaptation with Rank-Heterogeneous Communication</strong></a><br>
Yuji Byun and Jaeho Lee<br>
<strong>NAACL 2025</strong> (NeurIPS 2024 AFM Workshop)</p>
<p><a href="https://openreview.net/forum?id=Sr5XaZzirA"><strong>Fast Training of Sinusoidal Neural Fields via Scaling Initialization</strong></a><br>
Taesun Yeom,<sup>*</sup> Sangyoon Lee,<sup>*</sup> and Jaeho Lee<br>
<strong>ICLR 2025</strong></p>
<p><a href="https://openreview.net/forum?id=2OegVbwvY2"><strong>ZIP: An Efficient Zeroth-order Prompt Tuning for Black-box Vision-Language Models</strong></a><br>
Seonghwan Park, Jaehyeon Jeong, Yongjun Kim, Jaeho Lee, and Namhoon Lee<br>
<strong>ICLR 2025</strong></p>
<p><a href="https://arxiv.org/abs/2409.08199"><strong>AudioBERT: Audio Knowledge Augmented Language Model</strong></a><br>
Hyunjong Ok,<sup>*</sup> Suho Yoo,<sup>*</sup> and Jaeho Lee<br>
<strong>ICASSP 2025</strong> (Outstanding paper award üèÜ @ JKAIA 2024)<br>
<a href="https://github.com/HJ-Ok/AudioBERT">code</a>, <a href="https://github.com/HJ-Ok/AudioBERT/tree/main/dataset">dataset</a></p>
<p><a href="https://arxiv.org/abs/2307.10805"><strong>Communication-Efficient Split Learning via Adaptive Feature-wise Compression</strong></a><br>
Yongjeong Oh, Jaeho Lee, Christopher G. Brinton, and Yo-Seb Jeon<br>
<strong>IEEE TNNLS</strong></p>
<h3 id="2024">
  <strong>2024</strong>
  <a class="anchor" href="#2024">#</a>
</h3>
<p><a href="https://arxiv.org/abs/2406.18002"><strong>Decoding with Limited Teacher Supervision Requires Understanding When to Trust the Teacher</strong></a><br>
Hyunjong Ok, Jegwang Ryu and Jaeho Lee<br>
<strong>EMNLP 2024</strong></p>
<p><a href="https://arxiv.org/abs/2406.12016"><strong>Prefixing Attention Sinks can Mitigate Activation Outliers for Large Language Model Quantization</strong></a><br>
Seungwoo Son, Wonpyo Park, Woohyun Han, Kyuyeun Kim, and Jaeho Lee<br>
<strong>EMNLP 2024</strong></p>
<p><a href="https://arxiv.org/abs/2406.15524"><strong>Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization</strong></a><br>
Sungbin Shin, Wonpyo Park, Jaeho Lee, and Namhoon Lee<br>
<strong>EMNLP 2024</strong></p>
<p><a href="https://arxiv.org/abs/2302.10494"><strong>The Role of Masking for Efficient Supervised Knowledge Distillation of Vision Transformers</strong></a><br>
Seungwoo Son, Jegwang Ryu, Namhoon Lee, and Jaeho Lee<br>
<strong>ECCV 2024</strong> (ICLR 2023 Sparsity Workshop, Outstanding paper award ü•â @ IPIU 2023)<br>
<a href="https://maskedkd.github.io/">project page</a>, <a href="https://github.com/effl-lab/MaskedKD">code</a></p>
<p><a href="https://arxiv.org/abs/2403.02944"><strong>Neural Image Compression with Text-guided Encoding for both Pixel-level and Perceptual Fidelity</strong></a><br>
Hagyeong Lee,<sup>*</sup> Minkyu Kim,<sup>*</sup> Jun-Hyuk Kim, Seungeon Kim, Dokwan Oh, and Jaeho Lee<br>
<strong>ICML 2024</strong><br>
<a href="https://taco-nic.github.io/">project page</a>, <a href="https://github.com/effl-lab/TACO">code</a></p>
<p><a href="https://arxiv.org/abs/2402.05965"><strong>Hybrid Neural Representations for Spherical Data</strong></a><br>
Hyomin Kim, Yunhui Jang, Jaeho Lee, and Sungsoo Ahn<br>
<strong>ICML 2024</strong></p>
<p><a href="https://arxiv.org/abs/2311.17094"><strong>In Search of a Data Transformation that Accelerates Neural Field Training</strong></a><br>
Junwon Seo,<sup>*</sup> Sangyoon Lee,<sup>*</sup> Kwang In Kim, and Jaeho Lee<br>
<strong>CVPR 2024</strong> <code>Oral (top 0.78%)</code> (NeurIPS 2023 ATTRIB Workshop)<br>
<a href="https://github.com/effl-lab/DT4Neural-Field">code</a> <a href="https://huggingface.co/spaces/lyunm1206/Interactive_Loss_Landscapes">demo</a></p>
<p><a href="https://arxiv.org/abs/2301.11104"><strong>Discovering and Mitigating Visual Biases through Keyword Explanation</strong></a><br>
Younghyun Kim,<sup>*</sup> Sangwoo Mo,<sup>*</sup> Minkyu Kim, Kyungmin Lee, Jaeho Lee, and Jinwoo Shin<br>
<strong>CVPR 2024</strong> <code>Highlight (top 2.8%)</code> (ICML 2023 SCIS Workshop)<br>
<a href="https://github.com/alinlab/b2t">code</a></p>
<p><a href="https://arxiv.org/abs/2404.01914"><strong>SCANNER: Knowledge-Enhanced Approach for Robust Multi-modal Named Entity Recognition of Unseen Entities</strong></a><br>
Hyunjong Ok, Taeho Kil, Sukmin Seo, and Jaeho Lee<br>
<strong>NAACL 2024</strong></p>
<p><a href="https://arxiv.org/abs/2205.15567"><strong>Few-shot Unlearning</strong></a><br>
Youngsik Yoon, Jinhwan Nam, Hyojeong Yun, Jaeho Lee, Dongwoo Kim, and Jungseul Ok<br>
<strong>IEEE S&amp;P 2024</strong></p>
<p><a href="https://arxiv.org/abs/2404.07217"><strong>Attention-aware Semantic Communications for Collaborative Inference</strong></a><br>
Jiwoong Im,<sup>*</sup> Nayoung Kwon,<sup>*</sup> Taewoo Park, Jiheon Woo, Jaeho Lee, and Yongjune Kim<br>
<strong>IEEE IoT Journal</strong> (IEEE Communication Theory Workshop 2024)</p>
<p><a href="https://arxiv.org/abs/2409.09866"><strong>Constructing a Singing Style Captioning Dataset</strong></a><br>
Hyunjong Ok and Jaeho Lee<br>
arXiv 2409.09866<br>
<a href="https://github.com/HJ-Ok/S2cap">dataset</a></p>
<h3 id="2023">
  <strong>2023</strong>
  <a class="anchor" href="#2023">#</a>
</h3>
<p><a href="https://arxiv.org/abs/2302.00617"><strong>Learning Large-scale Neural Fields via Context Pruned Meta-learning</strong></a><br>
Jihoon Tack, Subin Kim, Sihyun Yu, Jaeho Lee, Jinwoo Shin, and Jonathan R. Schwarz<br>
<strong>NeurIPS 2023</strong> (ICLR 2023 Neural Fields Workshop)<br>
<a href="https://github.com/jihoontack/GradNCP">code</a></p>
<p><a href="https://openreview.net/forum?id=bBXCCSoVQZ"><strong>Modality-Agnostic Variational Compression of Implicit Neural Representations</strong></a><br>
Jonathan R. Schwarz, Jihoon Tack, Yee Whye Teh, Jaeho Lee, and Jinwoo Shin<br>
<strong>ICML 2023</strong> (ICLR 2023 Neural Fields Workshop)</p>
<p><a href="https://openreview.net/forum?id=VV4zJwLwI7"><strong>Breaking the Spurious Causality of Conditional Generation via Fairness Intervention with Corrective Sampling</strong></a><br>
Junhyun Nam, Sangwoo Mo, Jaeho Lee, and Jinwoo Shin<br>
<strong>TMLR 2023</strong> (ICML 2023 SCIS Workshop)</p>
<p><a href="https://unireps.org"><strong>Semi-Ensemble: A Simple Approach to Over-Parameterize Model Interpolation</strong></a><br>
Jiwoon Lee and Jaeho Lee<br>
<strong>NeurIPS 2023 Workshop</strong>: UniReps</p>
<p><a href="https://icml.cc/virtual/2023/25899"><strong>On the Effectiveness of Sharpness-aware Minimization with Large Mini-batches</strong></a><br>
Jinseok Chung, Seonghwan Park, Jaeho Lee, and Namhoon Lee<br>
<strong>ICML 2023 Workshop</strong>: HDLD</p>
<p><a href="https://arxiv.org/abs/2302.11187"><strong>Debiased Distillation by Transplanting the Last Layer</strong></a><br>
Jiwoon Lee and Jaeho Lee<br>
arXiv 2302.11187 (IPIU 2023)</p>
<h3 id="2022">
  <strong>2022</strong>
  <a class="anchor" href="#2022">#</a>
</h3>
<p><a href="https://openreview.net/forum?id=OxfI-3i5M8g"><strong>Scalable Neural Video Representations with Learnable Positional Features</strong></a><br>
Subin Kim, Sihyun Yu, Jaeho Lee, and Jinwoo Shin<br>
<strong>NeurIPS 2022</strong><br>
<a href="https://subin-kim-cv.github.io/NVP/">project page</a></p>
<p><a href="https://openreview.net/forum?id=FCNMbF_TsKm"><strong>Meta-learning with Self-improving Momentum Targets</strong></a><br>
Jihoon Tack, Jongjin Park, Hankook Lee, Jaeho Lee and Jinwoo Shin<br>
<strong>NeurIPS 2022</strong></p>
<p><a href="https://openreview.net/forum?id=_F9xpOrqyX9"><strong>Spread Spurious Attribute: Improving Worst-Group Accuracy with Spurious Attribute Estimation</strong></a><br>
Junhyun Nam, Jaehyung Kim, Jaeho Lee, and Jinwoo Shin<br>
<strong>ICLR 2022</strong></p>
<p><a href="https://arxiv.org/abs/2204.02405"><strong>Zero-shot Blind Image Denoising via Implicit Neural Representations</strong></a><br>
Chaewon Kim, Jaeho Lee, and Jinwoo Shin<br>
arXiv 2204.02405</p>
<h3 id="2021">
  <strong>2021</strong>
  <a class="anchor" href="#2021">#</a>
</h3>
<p><a href="https://openreview.net/forum?id=Tn0PnRY877g"><strong>Meta-learning Sparse Implicit Neural Representations</strong></a><br>
Jaeho Lee, Jihoon Tack, Namhoon Lee, and Jinwoo Shin<br>
<strong>NeurIPS 2021</strong></p>
<p><a href="https://openaccess.thecvf.com/content/ICCV2021/html/Cha_Co2L_Contrastive_Continual_Learning_ICCV_2021_paper.html"><strong>Co2L: Contrastive Continual Learning</strong></a><br>
Hyuntak Cha, Jaeho Lee, and Jinwoo Shin<br>
<strong>ICCV 2021</strong></p>
<p><a href="https://proceedings.mlr.press/v134/park21a.html"><strong>Provable Memorization via Deep Neural Networks using Sub-linear Parameters</strong></a><br>
Sejun Park, Jaeho Lee, Chulhee Yun, and Jinwoo Shin<br>
<strong>COLT 2021</strong> (DeepMath 2020 <code>Oral</code>)</p>
<p><a href="https://openreview.net/forum?id=O-XJwyoIF-k"><strong>Minimum Width for Universal Approximation</strong></a><br>
Sejun Park, Chulhee Yun, Jaeho Lee, and Jinwoo Shin<br>
<strong>ICLR 2021</strong> <code>Spotlight</code> (DeepMath 2020 <code>Oral</code>)</p>
<p><a href="https://openreview.net/forum?id=H6ATjJ0TKdf"><strong>Layer-adaptive Sparsity for the Magnitude-based Pruning</strong></a><br>
Jaeho Lee, Sejun Park, Sangwoo Mo, Sungsoo Ahn, and Jinwoo Shin<br>
<strong>ICLR 2021</strong></p>
<p><a href="https://ojs.aaai.org/index.php/AAAI/article/view/17601"><strong>MASKER: Masked Keyword Regularization for Reliable Text Generation</strong></a><br>
Seung Jun Moon, Sangwoo Mo, Kimin Lee, Jaeho Lee, and Jinwoo Shin<br>
<strong>AAAI 2021</strong></p>
<p><a href="https://sites.google.com/view/sparsity-workshop-2021/accepted-papers"><strong>Greedyprune: Layer-wise Optimization Algorithms for Magnitude-based Pruning</strong></a><br>
Vinoth Nandakumar and Jaeho Lee<br>
<strong>Sparse Neural Network Workshop 2021</strong></p>
<h3 id="2020">
  <strong>2020</strong>
  <a class="anchor" href="#2020">#</a>
</h3>
<p><a href="https://proceedings.neurips.cc/paper/2020/hash/9f60ab2b55468f104055b16df8f69e81-Abstract.html"><strong>Learning Bounds for Risk-sensitive Learning</strong></a><br>
Jaeho Lee, Sejun Park, and Jinwoo Shin<br>
<strong>NeurIPS 2020</strong></p>
<p><a href="https://papers.nips.cc/paper_files/paper/2020/hash/eddc3427c5d77843c2253f1e799fe933-Abstract.html"><strong>Learning from Failure: Training Debiased Classifier from Biased Classifier</strong></a><br>
Junhyun Nam, Hyuntak Cha, Sungsoo Ahn, Jaeho Lee, and Jinwoo Shin<br>
<strong>NeurIPS 2020</strong></p>
<p><a href="https://openreview.net/forum?id=ryl3ygHYDB"><strong>Lookahead: A Far-sighted Alternative of Magnitude-based Pruning</strong></a><br>
Sejun Park,<sup>*</sup> Jaeho Lee,<sup>*</sup> Sangwoo Mo, and Jinwoo Shin<br>
<strong>ICLR 2020</strong></p>
<h3 id="pre-2020">
  <strong>Pre-2020</strong>
  <a class="anchor" href="#pre-2020">#</a>
</h3>
<p><a href="https://epubs.siam.org/doi/10.1137/18M1234461"><strong>Learning Finite-dimensional Coding Schemes with Nonlinear Reconstruction Maps</strong></a><br>
Jaeho Lee and Maxim Raginsky<br>
<strong>SIMODS 2019</strong></p>
<p><a href="https://papers.nips.cc/paper_files/paper/2018/hash/ea8fcd92d59581717e06eb187f10666d-Abstract.html"><strong>Minimax Statistical Learning with Wasserstein Distances</strong></a><br>
Jaeho Lee and Maxim Raginsky<br>
<strong>NeurIPS 2018</strong> <code>Spotlight</code></p>
<p><a href="https://ieeexplore.ieee.org/document/7282992"><strong>On MMSE Estimation from Quantized Observations in the Nonasymptotic Regime</strong></a><br>
Jaeho Lee, Maxim Raginsky, and Pierre Moulin<br>
<strong>ISIT 2015</strong></p>
<h3 id="domestic-posters-">
  <strong>Domestic Posters üêØ</strong>
  <a class="anchor" href="#domestic-posters-">#</a>
</h3>
<hr>
<h4 id="an-empirical-study-on-the-bias-of-generative-image-compression">
  <strong>An Empirical Study on the Bias of Generative Image Compression</strong>
  <a class="anchor" href="#an-empirical-study-on-the-bias-of-generative-image-compression">#</a>
</h4>
<p>Hagyeong Lee and Jaeho Lee<br>
<strong>IPIU 2023</strong></p>
<h4 id="is-sparse-identification-model-sufficiently-biased">
  <strong>Is Sparse Identification Model Sufficiently Biased?</strong>
  <a class="anchor" href="#is-sparse-identification-model-sufficiently-biased">#</a>
</h4>
<p>Junwon Seo and Jaeho Lee<br>
<strong>IPIU 2023</strong></p>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">


  <div><a class="flex align-center" href="https://github.com/effl-lab/effl-lab.github.io/commit/f14ce817cccd6624b166a67c43809912ace32b4f" title='Last modified by EffL Lab @ POSTECH | January 24, 2025' target="_blank" rel="noopener">
      <img src="/svg/calendar.svg" class="book-icon" alt="Calendar" />
      <span>January 24, 2025</span>
    </a>
  </div>



  <div>
    <a class="flex align-center" href="https://github.com/effl-lab/effl-lab.github.io/edit/main//content/docs/research/papers.md" target="_blank" rel="noopener">
      <img src="/svg/edit.svg" class="book-icon" alt="Edit" />
      <span>Edit this page</span>
    </a>
  </div>


</div>



  <script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script>


 
        
      </footer>

      
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      <div class="book-toc-content">
        
  
<nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li>
          <ul>
            <li><a href="#2025"><strong>2025</strong></a></li>
            <li><a href="#2024"><strong>2024</strong></a></li>
            <li><a href="#2023"><strong>2023</strong></a></li>
            <li><a href="#2022"><strong>2022</strong></a></li>
            <li><a href="#2021"><strong>2021</strong></a></li>
            <li><a href="#2020"><strong>2020</strong></a></li>
            <li><a href="#pre-2020"><strong>Pre-2020</strong></a></li>
            <li><a href="#domestic-posters-"><strong>Domestic Posters üêØ</strong></a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>


 
      </div>
    </aside>
    
  </main>

  
</body>
</html>












